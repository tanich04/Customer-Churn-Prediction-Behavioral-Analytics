{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0d4d46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m {\n\u001b[32m      2\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mcells\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m   {\n\u001b[32m      4\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m      6\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m# Phase 3, Continued: Model Explainability (SHAP)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis notebook demonstrates the crucial step of model interpretability. We will use the SHAP (SHapley Additive exPlanations) library to understand and explain the predictions of our final churn model. This allows us to provide actionable insights to a business audience, moving beyond just a prediction score to the reasons behind it.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m   },\n\u001b[32m      8\u001b[39m   {\n\u001b[32m      9\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mnull\u001b[49m,\n\u001b[32m     11\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     12\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     13\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mimport sys\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mimport shap\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfrom joblib import load\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfrom sklearn.model_selection import train_test_split\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Add src directory to path\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33msys.path.append(\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../src\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfrom ingest_data import get_clean_data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfrom feature_engineering import create_engagement_features, one_hot_encode_categorical\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# --- 1. Load the Trained Model and Data ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Load the final model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mmodel = load(\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../models/XGBClassifier.joblib\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Prepare the data in the exact same way as in the training script\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mdata_path = \u001b[39m\u001b[33m'\u001b[39m\u001b[33m../data/CreditCardCustomers.csv\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mdf_clean = get_clean_data(data_path)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mdf_engineered = create_engagement_features(df_clean)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mcategorical_cols = [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mGender\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mEducation_Level\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mMarital_Status\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mIncome_Category\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mCard_Category\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mdf_final = one_hot_encode_categorical(df_engineered, columns=categorical_cols)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Separate features and target\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mX = df_final.drop(columns=[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mChurnStatus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mCustomerID\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33my = df_final[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mChurnStatus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Split data to get the test set for explaining predictions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m_, X_test, _, _ = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# --- 2. Use SHAP to explain the model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms output ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# The explainer object will calculate SHAP values for each feature\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mexplainer = shap.Explainer(model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mshap_values = explainer(X_test)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mGenerating SHAP summary plots...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Global feature importance summary (shows overall impact of each feature)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# This is a key visualization for a business audience\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mshap.summary_plot(shap_values, X_test, plot_type=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mbar\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Detailed summary plot (shows how each feature affects the output)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mshap.summary_plot(shap_values, X_test)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Local interpretability for a single customer (e.g., the first test customer)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# This plot explains why a specific customer was predicted to churn or not\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnGenerating SHAP waterfall plot for a single prediction...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mshap.plots.waterfall(shap_values[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Local interpretability for another specific customer (e.g., a customer predicted to churn)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# You can manually select an index of a churned customer from the test set for this.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnGenerating SHAP force plot for a single prediction...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mshap.initjs()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mshap.plots.force(shap_values[100])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m   }\n\u001b[32m     15\u001b[39m  ],\n\u001b[32m     16\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     17\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mkernelspec\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     18\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mdisplay_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPython 3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mlanguage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m   },\n\u001b[32m     22\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mlanguage_info\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     23\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcodemirror_mode\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mipython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m\n\u001b[32m     26\u001b[39m    },\n\u001b[32m     27\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mfile_extension\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmimetype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtext/x-python\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mnbconvert_exporter\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mpygments_lexer\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mipython3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     32\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m3.8.8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     33\u001b[39m   }\n\u001b[32m     34\u001b[39m  },\n\u001b[32m     35\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mnbformat\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m,\n\u001b[32m     36\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mnbformat_minor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m\n\u001b[32m     37\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": \"# Phase 3, Continued: Model Explainability (SHAP)\\n\\nThis notebook demonstrates the crucial step of model interpretability. We will use the SHAP (SHapley Additive exPlanations) library to understand and explain the predictions of our final churn model. This allows us to provide actionable insights to a business audience, moving beyond just a prediction score to the reasons behind it.\"\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": \"import pandas as pd\\nimport sys\\nimport shap\\nfrom joblib import load\\nfrom sklearn.model_selection import train_test_split\\n\\n# Add src directory to path\\nsys.path.append('../src')\\nfrom ingest_data import get_clean_data\\nfrom feature_engineering import create_engagement_features, one_hot_encode_categorical\\n\\n# --- 1. Load the Trained Model and Data ---\\n\\n# Load the final model\\nmodel = load('../models/XGBClassifier.joblib')\\n\\n# Prepare the data in the exact same way as in the training script\\ndata_path = '../data/CreditCardCustomers.csv'\\ndf_clean = get_clean_data(data_path)\\ndf_engineered = create_engagement_features(df_clean)\\ncategorical_cols = ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\\ndf_final = one_hot_encode_categorical(df_engineered, columns=categorical_cols)\\n\\n# Separate features and target\\nX = df_final.drop(columns=['ChurnStatus', 'CustomerID'])\\ny = df_final['ChurnStatus']\\n\\n# Split data to get the test set for explaining predictions\\n_, X_test, _, _ = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\\n\\n# --- 2. Use SHAP to explain the model's output ---\\n\\n# The explainer object will calculate SHAP values for each feature\\nexplainer = shap.Explainer(model)\\nshap_values = explainer(X_test)\\n\\nprint(\\\"Generating SHAP summary plots...\\\")\\n\\n# Global feature importance summary (shows overall impact of each feature)\\n# This is a key visualization for a business audience\\nshap.summary_plot(shap_values, X_test, plot_type=\\\"bar\\\")\\n\\n# Detailed summary plot (shows how each feature affects the output)\\nshap.summary_plot(shap_values, X_test)\\n\\n# Local interpretability for a single customer (e.g., the first test customer)\\n# This plot explains why a specific customer was predicted to churn or not\\nprint(\\\"\\\\nGenerating SHAP waterfall plot for a single prediction...\\\")\\nshap.plots.waterfall(shap_values[0])\\n\\n# Local interpretability for another specific customer (e.g., a customer predicted to churn)\\n# You can manually select an index of a churned customer from the test set for this.\\nprint(\\\"\\\\nGenerating SHAP force plot for a single prediction...\\\")\\nshap.initjs()\\nshap.plots.force(shap_values[100])\\n\"\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.8\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
